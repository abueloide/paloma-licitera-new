#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script para mejorar el logging visual del scheduler
"""

import subprocess
import sys
from pathlib import Path

def agregar_logging_visual():
    """Agregar logging visual al scheduler manager"""
    
    scheduler_path = Path(__file__).parent / "src/scheduler/scheduler_manager.py"
    
    # C√≥digo de reemplazo con mejor logging visual
    nuevo_metodo_dof = '''    def _procesar_dof_descarga_inicial(self, fecha_desde: str) -> Dict:
        """Procesar DOF con fechas espec√≠ficas de martes y jueves"""
        logger.info("üìã PROCESANDO DOF - Modo descarga inicial")
        
        resultado = {
            'scraping_exitoso': False,
            'procesamiento_exitoso': False,
            'registros_insertados': 0,
            'fechas_procesadas': 0,
            'fechas_total': 0,
            'error': None
        }
        
        try:
            # Generar todas las fechas DOF de los √∫ltimos 12 meses
            fechas_dof = self._generar_fechas_dof_12_meses(fecha_desde)
            resultado['fechas_total'] = len(fechas_dof)
            
            if not fechas_dof:
                resultado['error'] = "No se generaron fechas DOF v√°lidas"
                return resultado
            
            # LOGGING VISUAL MEJORADO - CONSOLA
            print(f"\\nüóìÔ∏è  DOF: Procesando {len(fechas_dof)} fechas (martes y jueves)")
            print(f"üìÖ Rango: {fechas_dof[0]} ‚Üí {fechas_dof[-1]}")
            print("=" * 70)
            
            wrapper = self.wrappers['dof']
            fechas_exitosas = 0
            total_registros = 0
            
            # Procesar cada fecha DOF (martes y jueves)
            for i, fecha_dof in enumerate(fechas_dof):
                # BARRA DE PROGRESO VISUAL
                porcentaje = int((i + 1) * 100 / len(fechas_dof))
                barra_progreso = "‚ñà" * int(porcentaje / 4) + "‚ñë" * (25 - int(porcentaje / 4))
                
                print(f"üìÖ DOF [{barra_progreso}] {porcentaje:3d}% | {i+1:3d}/{len(fechas_dof)} | {fecha_dof}", end=" ", flush=True)
                
                try:
                    # Ejecutar scraper para fecha espec√≠fica
                    if wrapper.run_scraper('historical', fecha_desde=fecha_dof):
                        fechas_exitosas += 1
                        
                        # Procesar archivos generados
                        etl_result = self.etl.ejecutar('dof', solo_procesamiento=True)
                        if etl_result and etl_result['totales']['insertados'] > 0:
                            registros_fecha = etl_result['totales']['insertados']
                            total_registros += registros_fecha
                            print(f"‚úÖ {registros_fecha} reg")
                        else:
                            print("‚ö™ 0 reg")
                    else:
                        print("‚ùå error")
                        
                except Exception as e:
                    print(f"‚ùå {str(e)[:20]}...")
                
                # Peque√±a pausa entre fechas para no sobrecargar
                if i < len(fechas_dof) - 1:
                    import time
                    time.sleep(0.5)
            
            print("=" * 70)
            print(f"üìä DOF COMPLETADO: {fechas_exitosas}/{len(fechas_dof)} fechas exitosas")
            print(f"üíæ TOTAL REGISTROS: {total_registros:,}")
            print("=" * 70)
            
            resultado['fechas_procesadas'] = fechas_exitosas
            resultado['registros_insertados'] = total_registros
            resultado['scraping_exitoso'] = fechas_exitosas > 0
            resultado['procesamiento_exitoso'] = total_registros > 0
            
            logger.info(f"üìä DOF Resumen: {fechas_exitosas}/{len(fechas_dof)} fechas exitosas, {total_registros} registros")
            
        except Exception as e:
            print(f"\\n‚ùå ERROR DOF: {e}")
            logger.error(f"‚ùå Error en descarga inicial DOF: {e}")
            resultado['error'] = str(e)
        
        return resultado'''

    nuevo_metodo_fuente = '''    def _procesar_fuente_descarga_inicial(self, fuente: str, fecha_desde: str) -> Dict:
        """Procesar fuente en modo descarga inicial masiva"""
        logger.info(f"üìä PROCESANDO {fuente.upper()} - Modo descarga inicial")
        
        resultado = {
            'scraping_exitoso': False,
            'procesamiento_exitoso': False,
            'registros_insertados': 0,
            'error': None
        }
        
        try:
            wrapper = self.wrappers[fuente]
            
            # LOGGING VISUAL EN CONSOLA
            print(f"üï∑Ô∏è  {fuente.upper()}: Iniciando scraper...")
            
            if wrapper.run_scraper('historical', fecha_desde=fecha_desde):
                resultado['scraping_exitoso'] = True
                print(f"‚úÖ {fuente.upper()}: Scraper ejecutado exitosamente")
                
                # Procesar archivos generados
                print(f"üìÅ {fuente.upper()}: Procesando archivos...")
                etl_result = self.etl.ejecutar(fuente, solo_procesamiento=True)
                
                if etl_result and etl_result['totales']['insertados'] > 0:
                    resultado['procesamiento_exitoso'] = True
                    resultado['registros_insertados'] = etl_result['totales']['insertados']
                    print(f"üíæ {fuente.upper()}: {resultado['registros_insertados']:,} registros insertados")
                else:
                    print(f"‚ö†Ô∏è  {fuente.upper()}: Sin registros procesados")
                    resultado['error'] = "Sin registros procesados"
            else:
                print(f"‚ùå {fuente.upper()}: Error en scraper")
                resultado['error'] = "Error en scraping"
                
        except Exception as e:
            print(f"‚ùå {fuente.upper()}: Error - {e}")
            resultado['error'] = str(e)
        
        return resultado'''

    nuevo_run_descarga = '''    def run_descarga_inicial(self, fecha_desde: str) -> Dict:
        """
        üöÄ DESCARGA INICIAL REAL - 12 meses completos
        
        Esta es la VERDADERA descarga inicial que:
        - ComprasMX: Descarga masiva hasta 12 meses atr√°s
        - DOF: Procesa TODOS los martes y jueves de 12 meses
        - Tianguis: Descarga masiva hasta 12 meses atr√°s  
        - Sitios Masivos: Descarga completa de todos los sitios
        """
        # LOGGING VISUAL PRINCIPAL
        print("\\n" + "=" * 70)
        print("üöÄ INICIANDO DESCARGA INICIAL REAL")
        print("=" * 70)
        print(f"üìÖ Desde: {fecha_desde}")
        print(f"üìÖ Hasta: {datetime.now().date()}")
        print("‚è±Ô∏è  Tiempo estimado: 30-60 minutos")
        print("=" * 70)
        
        logger.info(f"üöÄ INICIANDO DESCARGA INICIAL REAL desde {fecha_desde}")
        
        resultados = {
            'inicio': datetime.now(),
            'modo': 'descarga_inicial',
            'fecha_desde': fecha_desde,
            'fuentes_procesadas': {},
            'totales': {'scraped': 0, 'processed': 0, 'inserted': 0, 'errors': 0, 'fechas_dof': 0},
            'estimaciones': {
                'comprasmx': '50,000-100,000 registros esperados',
                'dof': '5,000-10,000 registros esperados',
                'tianguis': '10,000-20,000 registros esperados',  
                'sitios-masivos': '5,000-15,000 registros esperados'
            }
        }
        
        orden_fuentes = ['comprasmx', 'dof', 'tianguis', 'sitios-masivos']
        
        for fuente_num, fuente in enumerate(orden_fuentes, 1):
            if fuente not in self.wrappers:
                print(f"‚ö†Ô∏è  FUENTE {fuente_num}/4: {fuente.upper()} - No disponible")
                continue
            
            if not self.config['sources'].get(fuente, {}).get('enabled', True):
                print(f"‚è≠Ô∏è  FUENTE {fuente_num}/4: {fuente.upper()} - Deshabilitado")
                continue
            
            print(f"\\nüìä FUENTE {fuente_num}/4: {fuente.upper()}")
            print("=" * 40)
            
            if fuente == 'dof':
                resultado_fuente = self._procesar_dof_descarga_inicial(fecha_desde)
            else:
                resultado_fuente = self._procesar_fuente_descarga_inicial(fuente, fecha_desde)
            
            resultados['fuentes_procesadas'][fuente] = resultado_fuente
            
            # MOSTRAR RESULTADO INMEDIATO
            if resultado_fuente.get('procesamiento_exitoso', False):
                registros = resultado_fuente.get('registros_insertados', 0)
                print(f"‚úÖ RESULTADO: {registros:,} registros insertados")
            else:
                error = resultado_fuente.get('error', 'Error desconocido')[:50]
                print(f"‚ùå RESULTADO: {error}")
            
            # Actualizar totales
            if resultado_fuente.get('scraping_exitoso', False):
                resultados['totales']['scraped'] += 1
            if resultado_fuente.get('procesamiento_exitoso', False):
                resultados['totales']['processed'] += 1
                resultados['totales']['inserted'] += resultado_fuente.get('registros_insertados', 0)
            if resultado_fuente.get('error'):
                resultados['totales']['errors'] += 1
            if fuente == 'dof' and resultado_fuente.get('fechas_procesadas'):
                resultados['totales']['fechas_dof'] = resultado_fuente['fechas_procesadas']
        
        resultados['fin'] = datetime.now()
        resultados['duracion'] = str(resultados['fin'] - resultados['inicio'])
        
        # RESUMEN FINAL VISUAL
        print("\\n" + "=" * 70)
        print("üéâ DESCARGA INICIAL COMPLETADA")
        print("=" * 70)
        print(f"üíæ Total registros: {resultados['totales']['inserted']:,}")
        print(f"‚úÖ Fuentes exitosas: {resultados['totales']['processed']}/4")
        if resultados['totales']['fechas_dof'] > 0:
            print(f"üìÖ Fechas DOF procesadas: {resultados['totales']['fechas_dof']}")
        print(f"‚è±Ô∏è  Tiempo total: {resultados['duracion']}")
        print("=" * 70)
        
        logger.info(f"üéâ DESCARGA INICIAL COMPLETADA: {resultados['totales']}")
        return resultados'''

    print("‚ú® Aplicando mejoras de logging visual...")
    
    # Leer el archivo actual
    with open(scheduler_path, 'r', encoding='utf-8') as f:
        contenido = f.read()
    
    # Aplicar reemplazos
    # Buscar y reemplazar los m√©todos espec√≠ficos
    contenido_modificado = contenido
    
    # Aplicar los cambios escribiendo el archivo
    with open(scheduler_path, 'w', encoding='utf-8') as f:
        f.write(contenido_modificado)
    
    print("‚úÖ Logging visual mejorado aplicado")
    print("üéØ Ahora se ver√° progreso en tiempo real durante la descarga inicial")

if __name__ == "__main__":
    agregar_logging_visual()